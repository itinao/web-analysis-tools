name: run lighthouse and upload

on:
  schedule:
    - cron:  '*/5 * * * *'
jobs:
  run:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        device-type: ['desktop', 'mobile']
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 15
      - name: install
        run: node -v && yarn install
      - name: run lh
        run: yarn run lh-parallel -c 3 -d ${{ matrix.device-type }}
      - name: upload data
        if: always()
        env:
          PROJECT_ID: ${{ secrets.GOOGLE_PROJECT_ID }}
          CREDENTIALS_DATA: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
          DATASET_ID: ${{ secrets.GOOGLE_BIGQUERY_DATASET_ID }}
        run: |
          echo "$CREDENTIALS_DATA" | base64 --decode > /tmp/config.json
          yarn run upload-bigquery -p "$PROJECT_ID" -k /tmp/config.json -i "$DATASET_ID" -f dist/lh-${{ matrix.device-type }}.jsonl
